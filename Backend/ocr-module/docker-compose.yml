services:
  # Tesseract OCR service
  tesseract:
    image: tesseractshadow/tesseract4re:latest
    container_name: tesseract
    platform: linux/amd64
    ports:
      - "9090:9090"
    volumes:
      - ./temp/uploaded_files:/input
      - ./temp/resultats_reconnaissance:/output
    environment:
      TESSDATA_PREFIX: /usr/share/tesseract-ocr/4.00/tessdata
      TESSERACT_LANGUAGE: ${TESSERACT_LANGUAGE:-eng+fra+ar}  # Specify languages for OCR
    networks:
      - ocr-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090"]
      interval: 30s
      timeout: 10s
      retries: 5

  # MySQL Database with persistent volume for data storage
  db:
    image: mysql:8
    container_name: db-instance
    environment:
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/mysql_root_password
      MYSQL_DATABASE: shared_database
      MYSQL_USER: root
      MYSQL_PASSWORD: ''
    ports:
      - "3307:3306"
    volumes:
      - mysql_data:/var/lib/mysql  # Persistent data storage
    secrets:
      - mysql_root_password
    networks:
      - ocr-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Zookeeper service for Kafka
  zookeeper:
    image: arm64v8/zookeeper  # ARM-compatible image for Zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - ocr-network
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181", "|", "grep", "imok"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kafka service for event-driven OCR task distribution
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper
    networks:
      - ocr-network
    platform: linux/amd64

  # TensorFlow Model Serving
  tensorflow-serving:
    image: emacski/tensorflow-serving:latest  # ARM-compatible image
    container_name: tensorflow-serving
    ports:
      - "8501:8501"  # REST API port for model serving
    volumes:
      - ./tensorflow/models:/models/model  # Model files shared with retraining
    environment:
      - MODEL_NAME=model
      - MODEL_BASE_PATH=/models/model
      - TF_SERVING_VERSION_POLICY=latest  # Serve the latest model version
    networks:
      - ocr-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/v1/models/model"]
      interval: 30s
      timeout: 10s
      retries: 5

  # TensorFlow Model Retraining
  tensorflow-retrain:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: tensorflow-retrain
    volumes:
      - ./trainer/data:/trainer/data  # Training data for retraining
      - ./tensorflow/models:/models/model  # Ensure retraining uses the same volume
    networks:
      - ocr-network
    command: >
      /bin/bash -c "
      source /app/venv/bin/activate &&
      python3 /trainer/retrain_model.py
      "

  # OCR Module Service
  ocr-module:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ocr-module
    ports:
      - "8502:8502"
    networks:
      - ocr-network
    depends_on:
      - db
      - tensorflow-serving
      - kafka
    deploy:
      resources:
        limits:
          cpus: '0.5'        # Limit to 50% of a CPU
          memory: 512M       # Limit to 512MB of memory

  # Logging and Monitoring with ELK (ElasticSearch, Logstash, Kibana)
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.2-arm64
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"  # Elasticsearch
    networks:
      - ocr-network
    volumes:
      - es_data:/usr/share/elasticsearch/data  # Persistent storage for Elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.6.2-arm64
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"  # Kibana Dashboard
    networks:
      - ocr-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.6.2-arm64
    container_name: logstash
    environment:
     LS_JAVA_OPTS: "-Xmx256m -Xms256m"  # Define JVM options
    ports:
      - "5044:5044"  # Logstash
    networks:
      - ocr-network

# Persistent volumes for data storage
volumes:
  mysql_data:  # Persistent volume for MySQL
  es_data:     # Persistent volume for Elasticsearch

# Secrets for secure database credentials
secrets:
  mysql_root_password:
    file: ./secrets/mysql_root_password.txt

# Networks to ensure services communicate in isolation
networks:
  ocr-network:
    driver: bridge
